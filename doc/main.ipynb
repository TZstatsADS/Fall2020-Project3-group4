{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib.image as img\n",
    "import scipy.io\n",
    "import pickle\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: set work directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide directories for training images. Training images and Training fiducial points will be in different subfolders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change train_dir to where you have the train set because we can't\n",
    "#upload the train set to github\n",
    "train_dir = \"/Users/rohan/Desktop/train_set/\"\n",
    "train_image_dir = train_dir+\"images/\"\n",
    "train_pt_dir = train_dir+\"points/\"\n",
    "train_label_path = train_dir+\"label.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: set up controls for evaluation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chunk, we have a set of controls for the evaluation experiments. \n",
    "\n",
    "+ (T/F) cross-validation on the training set\n",
    "+ (T/F) reweighting the samples for training set \n",
    "+ (number) K, the number of CV folds\n",
    "+ (T/F) process features for training set\n",
    "+ (T/F) run evaluation on an independent test set\n",
    "+ (T/F) process features for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cv = True # run cross-validation on the training set\n",
    "sample_reweight = True # run sample reweighting in model training\n",
    "K = 5  # number of CV folds\n",
    "run_feature_train = True # process features for training set\n",
    "run_test = True # run evaluation on an independent test set\n",
    "run_feature_test = True # process features for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross-validation or independent test set evaluation, we compare the performance of models with different specifications. In this Starter Code, we tune parameter lambda (the amount of shrinkage) for logistic regression with LASSO penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of using these lambda for LASSO like in the starter code\n",
    "#we'll use these lambda for improving the baseline gradient boosting model\n",
    "\n",
    "lmbd = [1e-3, 5e-3, 1e-2, 5e-2, 1e-1]\n",
    "model_labels = [\"Gradient Boosting with learning rate = \"+str(x) for x in lmbd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: import data and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(train_label_path)\n",
    "n = info.shape[0]\n",
    "\n",
    "#we could use sklearn train_test_split here instead of doing it\n",
    "#manually like in the starter code\n",
    "n_train = int(round(n*(4/5),0))\n",
    "train_idx = np.random.choice(list(info.index),size=n_train,replace=False)\n",
    "test_idx = list(set(list(info.index))-set(train_idx)) #set difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you choose to extract features from images, such as using Gabor filter, R memory will exhaust all images are read together. The solution is to repeat reading a smaller batch(e.g 100) and process them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(os.listdir(train_image_dir))\n",
    "\n",
    "image_list = []\n",
    "for i in range(1,101): # 1 to 100\n",
    "    image = img.imread(train_image_dir+'{:04d}'.format(i)+'.jpg')\n",
    "    image_list.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiducial points are stored in matlab format. In this step, we read them and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to read fiducial points\n",
    "#input: index\n",
    "#output: matrix of fiducial points corresponding to the index\n",
    "\n",
    "def readMat_matrix(index):\n",
    "    try:\n",
    "        mat_data = scipy.io.loadmat(train_pt_dir+'{:04d}'.format(index)+'.mat')['faceCoordinatesUnwarped']\n",
    "    except KeyError:\n",
    "        mat_data = scipy.io.loadmat(train_pt_dir+'{:04d}'.format(index)+'.mat')['faceCoordinates2']\n",
    "    return np.matrix.round(mat_data,0)\n",
    "\n",
    "#load fiducial points\n",
    "#pickle is the closest equivalent to .RData that I could find in Python\n",
    "fiducial_pt_list = list(map(readMat_matrix,list(range(1,n_files+1))))\n",
    "pickle.dump(fiducial_pt_list, open( \"../output/fiducial_pt_list.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: construct features and responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The follow plots show how pairwise distance between fiducial points can work as feature for facial emotion recognition.\n",
    "\n",
    "  + In the first column, 78 fiducials points of each emotion are marked in order. \n",
    "  + In the second column distributions of vertical distance between right pupil(1) and  right brow peak(21) are shown in  histograms. For example, the distance of an angry face tends to be shorter than that of a surprised face.\n",
    "  + The third column is the distributions of vertical distances between right mouth corner(50)\n",
    "and the midpoint of the upper lip(52).  For example, the distance of an happy face tends to be shorter than that of a sad face.\n",
    "\n",
    "![Figure1](../figs/feature_visualization.jpg)\n",
    "\n",
    "`feature.R` should be the wrapper for all your feature engineering functions and options. The function `feature( )` should have options that correspond to different scenarios for your project and produces an R object that contains features and responses that are required by all the models you are going to evaluate later. \n",
    "  \n",
    "  + `feature.R`\n",
    "  + Input: list of images or fiducial point\n",
    "  + Output: an RData file that contains extracted features and corresponding responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: make this function into its own file feature.ipynb \n",
    "#since feature.R is a separate file in the starter code\n",
    "\n",
    "def feature(index, input_list = fiducial_pt_list):\n",
    "    ### Construct process features for training images \n",
    "\n",
    "    ### Input: a list of images or fiducial points; index: train index or test index\n",
    "\n",
    "    ### Output: a data frame containing: features and a column of label\n",
    "\n",
    "    ### here is an example of extracting pairwise distances between fiducial points\n",
    "    ### Step 1: Write a function pairwise_dist to calculate pairwise distance of items in a vector\n",
    "    def pairwise_dist(vec):\n",
    "        n = len(vec)\n",
    "        dist_matrix = pairwise_distances(np.array(vec).reshape(-1,1))\n",
    "        return list(dist_matrix[np.triu_indices(n,k=1)])\n",
    "    \n",
    "    ### Step 2: Write a function pairwise_dist_result to apply function in Step 1 to column of a matrix \n",
    "    def pairwise_dist_result(mat):\n",
    "        ### input: a n*2 matrix(e.g. fiducial_pt_list[[1]]), output: a vector(length n(n-1))\n",
    "        return list(np.transpose(np.apply_along_axis(pairwise_dist,0,mat)).flatten())\n",
    "    \n",
    "    ### Step 3: Apply function in Step 2 to selected index of input list, output: a feature matrix with ncol = n(n-1) = 78*77 = 6006\n",
    "    pairwise_dist_feature = ((np.array(list(map(pairwise_dist_result, [input_list[i] for i in index])))))\n",
    "    pairwise_dist_feature.shape\n",
    "    \n",
    "    colnames = ['feature'+str(i) for i in range(pairwise_dist_feature.shape[1])]\n",
    "    df = pd.DataFrame(pairwise_dist_feature,columns=colnames)\n",
    "    label_df = pd.DataFrame(list(info['label'].iloc[index]),columns=['labels'])\n",
    "    \n",
    "    pairwise_data = pd.concat([df,label_df],axis=1)\n",
    "    return pairwise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_feature_train = np.nan\n",
    "if run_feature_train == True:\n",
    "    start = time.time()\n",
    "    dat_train = feature(train_idx, fiducial_pt_list)\n",
    "    end = time.time()\n",
    "    tm_feature_train = end-start\n",
    "    pickle.dump(dat_train, open( \"../output/feature_train.p\", \"wb\" ) )\n",
    "else:\n",
    "    pickle.load(open(\"../output/feature_train.p\", \"rb\"))\n",
    "    \n",
    "    \n",
    "tm_feature_test = np.nan\n",
    "if run_feature_test == True:\n",
    "    start = time.time()\n",
    "    dat_test = feature(test_idx, fiducial_pt_list)\n",
    "    end = time.time()\n",
    "    tm_feature_test = end-start\n",
    "    pickle.dump(dat_test, open( \"../output/feature_test.p\", \"wb\" ) )\n",
    "else:\n",
    "    pickle.load(open(\"../output/feature_test.p\", \"rb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train a classification model with training features and responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the train model and test model from library. \n",
    "\n",
    "`train.R` and `test.R` should be wrappers for all your model training steps and your classification/prediction steps. \n",
    "\n",
    "+ `train.R`\n",
    "  + Input: a data frame containing features and labels and a parameter list.\n",
    "  + Output:a trained model\n",
    "+ `test.R`\n",
    "  + Input: the fitted classification model using training data and processed features from testing images \n",
    "  + Input: an R object that contains a trained classifier.\n",
    "  + Output: training model specification\n",
    "\n",
    "+ In this Starter Code, we use logistic regression with LASSO penalty to do classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection with cross-validation\n",
    "* Do model selection by choosing among different values of training model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#implementing GBM instead of lasso\\ndef train(features, labels, l = 1):\\n    model = GradientBoostingClassifier(n_estimators=50,max_depth= 10,learning_rate=l)\\n    model = model.fit(train_x,train_y) \\n    model.fit(features,labels)\\n    return model\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Problem : sklearn lasso function doesn't have a weights argument.\n",
    "In the starter code they use R's glmnet which does have weights argument.\n",
    "We need to implement gbm instead of lasso for baseline model anyway\n",
    "so this isn't really a big issue.\n",
    "\n",
    "\n",
    "def train(features, labels, w = np.nan, l = 1):\n",
    "    model = linear_model.Lasso(alpha = l)\n",
    "    model.fit(features,labels)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#implementing GBM instead of lasso\n",
    "def train(features, labels, l = 1):\n",
    "    model = GradientBoostingClassifier(n_estimators=50,max_depth= 10,learning_rate=l)\n",
    "    model = model.fit(train_x,train_y) \n",
    "    model.fit(features,labels)\n",
    "    return model\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMaybe we can just use grid search and model scores from sklearn\\ninstead of defining our own cv_function\\n\\nStarter code cv_function (UNFINISHED)\\n\\ndef cv_function(features, labels, K, l, reweight = False):\\n    ### Input:\\n    ### - features: feature data frame\\n    ### - labels: label data vector\\n    ### - K: a number stands for K-fold CV\\n    ### - l: tuning parameters \\n    ### - reweight: sample reweighting \\n    \\n    random.seed(2020)\\n    n = features.shape[0]\\n    n_fold = int(round(n/K,0))\\n    s = 1+(np.random.choice(list(range(1,n+1)),size=n,replace=False)%K)\\n    cv_error = [np.nan]*K\\n    cv_AUC = [np.nan]*K\\n    \\n    for i in range(0,K):\\n        ## create features and labels for train/test\\n        feature_train = features.iloc[s != i]\\n        feature_test = features.iloc[s == i]\\n        label_train = [x for x in labels if s != i]\\n        label_test = [x for x in labels if s == i]\\n    \\n    weight_train = [np.nan]*label_train.shape[0]\\n    weight_test = [np.nan]*label_test.shape[0]\\n    \\n    fow\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Maybe we can just use grid search and model scores from sklearn\n",
    "instead of defining our own cv_function\n",
    "\n",
    "Starter code cv_function (UNFINISHED)\n",
    "\n",
    "def cv_function(features, labels, K, l, reweight = False):\n",
    "    ### Input:\n",
    "    ### - features: feature data frame\n",
    "    ### - labels: label data vector\n",
    "    ### - K: a number stands for K-fold CV\n",
    "    ### - l: tuning parameters \n",
    "    ### - reweight: sample reweighting \n",
    "    \n",
    "    random.seed(2020)\n",
    "    n = features.shape[0]\n",
    "    n_fold = int(round(n/K,0))\n",
    "    s = 1+(np.random.choice(list(range(1,n+1)),size=n,replace=False)%K)\n",
    "    cv_error = [np.nan]*K\n",
    "    cv_AUC = [np.nan]*K\n",
    "    \n",
    "    for i in range(0,K):\n",
    "        ## create features and labels for train/test\n",
    "        feature_train = features.iloc[s != i]\n",
    "        feature_test = features.iloc[s == i]\n",
    "        label_train = [x for x in labels if s != i]\n",
    "        label_test = [x for x in labels if s == i]\n",
    "    \n",
    "    weight_train = [np.nan]*label_train.shape[0]\n",
    "    weight_test = [np.nan]*label_test.shape[0]\n",
    "    \n",
    "    fow\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = dat_train.loc[:, dat_train.columns != 'labels']\n",
    "label_train = dat_train['labels']\n",
    "\n",
    "feature_test = dat_test.loc[:, dat_test.columns != 'labels']\n",
    "label_test = dat_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do a grid search for optimal parameters\n",
    "#takes a really long time and we don't know the features yet\n",
    "#so i commented the grid search out for now\n",
    "if (run_cv):\n",
    "    params = {'learning_rate':lmbd, 'max_depth': [1,2,3,4], 'n_estimators':[100,200,300,400,500]}\n",
    "    #gscv = GridSearchCV(GradientBoostingClassifier(),params,cv=K).fit(feature_train,label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 82.357947 seconds\n"
     ]
    }
   ],
   "source": [
    "#Baseline model\n",
    "#need to cross validate to get optimal parameters though\n",
    "\n",
    "start = time.time()\n",
    "gbm=GradientBoostingClassifier(learning_rate=0.1,max_depth=2,n_estimators=100)\n",
    "gbm.fit(feature_train,label_train)\n",
    "end = time.time()\n",
    "\n",
    "print('Training time {:4f} seconds'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18833333333333332"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds=gbm.predict(feature_test)\n",
    "np.mean(np.array(test_preds)!=np.array(label_test)) #Classification Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.score(feature_test,label_test)\n",
    "#score is 1-classification error i.e.\n",
    "#1-(np.mean(np.array(test_preds)!=np.array(label_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       473\n",
      "           1       0.75      0.17      0.27       127\n",
      "\n",
      "    accuracy                           0.81       600\n",
      "   macro avg       0.78      0.58      0.58       600\n",
      "weighted avg       0.80      0.81      0.76       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test,test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[466,   7],\n",
       "       [106,  21]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(label_test,test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
