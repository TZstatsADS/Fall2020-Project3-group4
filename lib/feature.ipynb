{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_initial(input_list, index, info = np.nan):\n",
    "    ### Construct initial features for training images \n",
    "    ### Input: input_list: a list of fiducial points; index: train index or test index; \n",
    "    ###        info: optional labeled data frame\n",
    "    ### Output: a data frame containing: features and a column of label (if info is not provided, then only features)\n",
    "\n",
    "    ### Step 1: Write a function pairwise_dist to calculate pairwise distance of items in a vector\n",
    "    def pairwise_dist(vec):\n",
    "        n = len(vec)\n",
    "        dist_matrix = pairwise_distances(np.array(vec).reshape(-1,1),metric='euclidean')\n",
    "        return list(dist_matrix[np.triu_indices(n,k=1)])\n",
    "    \n",
    "    ### Step 2: Write a function pairwise_dist_result to apply function in Step 1 to column of a matrix \n",
    "    def pairwise_dist_result(mat):\n",
    "        ### input: a n*2 matrix(e.g. fiducial_pt_list[[1]]), output: a vector(length n(n-1))\n",
    "        return list(np.transpose(np.apply_along_axis(pairwise_dist,0,mat)).flatten())\n",
    "    \n",
    "    ### Step 3: Apply function in Step 2 to selected index of input list, output: a feature matrix with ncol = n(n-1) = 78*77 = 6006\n",
    "    pairwise_dist_feature = ((np.array(list(map(pairwise_dist_result, [input_list[i] for i in index])))))\n",
    "    pairwise_dist_feature.shape\n",
    "    \n",
    "    colnames = ['feature'+str(i) for i in range(pairwise_dist_feature.shape[1])]\n",
    "    df = pd.DataFrame(pairwise_dist_feature,columns=colnames)\n",
    "    #if there's a label column then include it in the output, otherwise don't include a label column\n",
    "    try:\n",
    "        label_df = pd.DataFrame(list(info['label'].iloc[index]),columns=['labels'])\n",
    "        pairwise_data = pd.concat([df,label_df],axis=1)\n",
    "    except:\n",
    "        pairwise_data = df\n",
    "        \n",
    "    return pairwise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_improved(input_list, index, info=np.nan):\n",
    "    ### Construct process features for training images \n",
    "    ### Input: a list of images or fiducial points; index: train index or test index\n",
    "    ### Output: a data frame containing: features and a column of label\n",
    "\n",
    "    ### Step 1: Write a function pairwise_dist to calculate pairwise distance of items in a matrix\n",
    "    ### For every two points p1 and p2, the distance=sqrt((p1[0]-p2[0])**2+(p1[1]-p2[1])**2)\n",
    "    def pairwise_dist(mat):\n",
    "        ### input: a n*2 matrix(e.g. fiducial_pt_list[[1]]), output: a vector(length n(n-1)/2)\n",
    "        dist = pdist(mat)\n",
    "        return dist\n",
    "    \n",
    "    ### Step 2: Apply function in Step 1 to selected index of input list, output: a feature matrix with ncol = n(n-1)/2 = 78*77/2 = 3003\n",
    "    pairwise_dist_feature = ((np.array(list(map(pairwise_dist, [input_list[i] for i in index])))))\n",
    "    pairwise_dist_feature.shape\n",
    "    \n",
    "    colnames = ['feature'+str(i) for i in range(pairwise_dist_feature.shape[1])]\n",
    "    df = pd.DataFrame(pairwise_dist_feature,columns=colnames)\n",
    "    #if there's a label column then include it in the output, otherwise don't include a label column\n",
    "    try:\n",
    "        label_df = pd.DataFrame(list(info['label'].iloc[index]),columns=['labels'])\n",
    "        pairwise_data = pd.concat([df,label_df],axis=1)\n",
    "    except:\n",
    "        pairwise_data = df\n",
    "        \n",
    "    return pairwise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is only applied to labeled training data\n",
    "#SMOTE is not used on test data\n",
    "\n",
    "def feature_SMOTE(dat_train):    \n",
    "    \n",
    "    feature_train = dat_train.loc[:, dat_train.columns != 'labels']\n",
    "    label_train = dat_train['labels'] \n",
    "    over = SMOTE(sampling_strategy='auto')\n",
    "    under = RandomUnderSampler(sampling_strategy='auto')\n",
    "    sm = Pipeline(steps = [('o', over), ('u', under)])\n",
    "    \n",
    "    feature_train_sm, label_train_sm = sm.fit_resample(feature_train,label_train)\n",
    "    \n",
    "    colnames = ['feature'+str(i) for i in range(feature_train_sm.shape[1])]\n",
    "    df = pd.DataFrame(feature_train_sm,columns=colnames)\n",
    "    label_df = pd.DataFrame(list(label_train_sm),columns=['labels'])\n",
    "    \n",
    "    SMOTE_data = pd.concat([df,label_df],axis=1)\n",
    "    return SMOTE_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_PCA(dat_train, dat_test):\n",
    "    \n",
    "    #train data transformation\n",
    "    start = time.time()\n",
    "\n",
    "    feature_train = dat_train.loc[:, dat_train.columns != 'labels']\n",
    "    label_train = dat_train['labels'] \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    feature_train_scaled = scaler.fit_transform(feature_train)\n",
    "    pca = PCA(n_components = 0.95, svd_solver='full').fit(feature_train_scaled)\n",
    "    feature_train_PCA = pca.transform(feature_train_scaled)\n",
    "    \n",
    "    colnames = ['feature'+str(i) for i in range(feature_train_PCA.shape[1])]\n",
    "    df = pd.DataFrame(feature_train_PCA,columns=colnames)\n",
    "    label_df = pd.DataFrame(list(label_train),columns=['labels'])\n",
    "    dat_train_PCA = pd.concat([df,label_df],axis = 1)\n",
    "    \n",
    "    end = time.time()\n",
    "    tm_feature_train_PCA = end-start\n",
    "       \n",
    "    #test data transformation\n",
    "    start = time.time()\n",
    "    \n",
    "    feature_test = dat_test.loc[:, dat_test.columns != 'labels']\n",
    "    label_test = dat_test['labels']\n",
    "    feature_test_scaled = scaler.fit_transform(feature_test)\n",
    "    feature_test_PCA = pca.transform(feature_test_scaled)\n",
    "    \n",
    "    colnames = ['feature'+str(i) for i in range(feature_test_PCA.shape[1])]\n",
    "    df = pd.DataFrame(feature_test_PCA,columns=colnames)\n",
    "    label_df = pd.DataFrame(list(label_test),columns=['labels'])\n",
    "    dat_test_PCA = pd.concat([df,label_df],axis = 1)\n",
    "\n",
    "    end = time.time()\n",
    "    tm_feature_test_PCA = end-start\n",
    "    \n",
    "    return [dat_train_PCA, dat_test_PCA, tm_feature_train_PCA, tm_feature_test_PCA]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
